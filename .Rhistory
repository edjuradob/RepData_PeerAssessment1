result <- rbind(result,cor(dat$sulfate, dat$nitrate,use = "everything"))
}
}
## Return a numeric vector of correlations
result
}
cr <- corr("specdata", 150)
#print(class(cr))
head(cr)
summary(cr)
corr <- function(directory, threshold = 0) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'threshold' is a numeric vector of length 1 indicating the
## number of completely observed observations (on all
## variables) required to compute the correlation between
## nitrate and sulfate; the default is 0
source("complete.R")
allfiles <- list.files(directory,full.names=T)
nobs<-complete(directory)
len<-length(nobs$id)
result<-vector()
#print(nobs)
for (i in 1:len){
if (nobs$nobs[i]>=threshold){
dat<-read.csv(allfiles[i])
dat<-dat[complete.cases(dat),]
result <- rbind(result,cor(dat$sulfate, dat$nitrate,use = "everything"))
}
}
## Return a numeric vector of correlations
result<-sapply(result[1], as.numeric)
}
cr <- corr("specdata", 150)
print(class(cr))
corr <- function(directory, threshold = 0) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'threshold' is a numeric vector of length 1 indicating the
## number of completely observed observations (on all
## variables) required to compute the correlation between
## nitrate and sulfate; the default is 0
source("complete.R")
allfiles <- list.files(directory,full.names=T)
nobs<-complete(directory)
len<-length(nobs$id)
result<-vector()
#print(nobs)
for (i in 1:len){
if (nobs$nobs[i]>=threshold){
dat<-read.csv(allfiles[i])
dat<-dat[complete.cases(dat),]
result <- rbind(result,cor(dat$sulfate, dat$nitrate,use = "everything"))
}
}
## Return a numeric vector of correlations
result<-sapply(result[1], as.numeric)
}
cr <- corr("specdata", 150)
print(class(cr))
head(cr)
summary(cr)
submit
submit()
submit()
corr <- function(directory, threshold = 0) {
}
submit()
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
cr <- corr("specdata", 400)
head(cr)
summary(cr)
cr <- corr("specdata", 150)
head(cr)
corr <- function(directory, threshold = 0) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'threshold' is a numeric vector of length 1 indicating the
## number of completely observed observations (on all
## variables) required to compute the correlation between
## nitrate and sulfate; the default is 0
source("complete.R")
allfiles <- list.files(directory,full.names=T)
nobs<-complete(directory)
len<-length(nobs$id)
result<-vector()
#print(nobs)
for (i in 1:len){
if (nobs$nobs[i]>=threshold){
dat<-read.csv(allfiles[i])
dat<-dat[complete.cases(dat),]
result <- rbind(result,cor(dat$sulfate, dat$nitrate,use = "everything"))
}
}
## Return a numeric vector of correlations
result<-sapply(result, as.numeric)
}
cr <- corr("specdata", 400)
head(cr)
corr <- function(directory, threshold = 0) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'threshold' is a numeric vector of length 1 indicating the
## number of completely observed observations (on all
## variables) required to compute the correlation between
## nitrate and sulfate; the default is 0
source("complete.R")
allfiles <- list.files(directory,full.names=T)
nobs<-complete(directory)
len<-length(nobs$id)
result<-vector()
#print(nobs)
for (i in 1:len){
if (nobs$nobs[i]>threshold){
dat<-read.csv(allfiles[i])
dat<-dat[complete.cases(dat),]
result <- rbind(result,cor(dat$sulfate, dat$nitrate,use = "everything"))
}
}
## Return a numeric vector of correlations
result<-sapply(result, as.numeric)
}
#cr <- corr("specdata", 150)
#print(class(cr))
#head(cr)
#summary(cr)
cr <- corr("specdata", 400)
head(cr)
submit()
submit()
submit()
mt<-matrix(c(2,1,0,1,1,1,0,1,2), nrow=3)
solve(mt)
mt<-matrix(c(2,3,5,0,0,1,1,0,1), nrow=3)
mt
solve(mt)
## Put comments here that give an overall description of what your
## functions do
##
## Write a short comment describing this function
## This function is something similar to a class, you have to
## "instantiate" it in a variable or symbol, and then access its inner
## functions as getters and setters.
## set() gives the value to the matrix, receiving a matrix as parameter
## get() returns the matrix
## setinverse() sets the inverse of the intern matrix
## getinverse()
makeCacheMatrix <- function(x = matrix()) {
inverse<-NULL
set <- function(mtx) {
innernmatrix <<- mtx
inverse <<- NULL
}
get <- function() internmatrix
setinverse <- function(solve) inverse <<- cacheSolve
getinverse <- function() inverse
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
## Write a short comment describing this function
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inverse <- x$getinverse()
if(!is.null(inverse)) {
message("getting cached data")
return(inverse)
}
data <- x$get()
inverse <- solve(data, ...)
x$setinverse(inverse)
inverse
}
m<-makeCacheMatrix()
m$set(mt)
m$get()
## Write a short comment describing this function
## This function is something similar to a class, you have to
## "instantiate" it in a variable or symbol, and then access its inner
## functions as getters and setters.
## set() gives the value to the matrix, receiving a matrix as parameter
## get() returns the matrix
## setinverse() sets the inverse of the intern matrix
## getinverse()
makeCacheMatrix <- function(x = matrix()) {
inverse<-NULL
set <- function(mtx) {
internmatrix <<- mtx
inverse <<- NULL
}
get <- function() internmatrix
setinverse <- function(solve) inverse <<- cacheSolve
getinverse <- function() inverse
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
m<-makeCacheMatrix()
m$set(mt)
m$get()
## set() gives the value to the matrix, receiving a matrix as parameter
makeCacheMatrix <- function(x = matrix()) {
inverse<-NULL
set <- function(mtx) {
internmatrix <<- mtx
inverse <<- NULL
}
get <- function() internmatrix
setinverse <- function(solve) inverse <<- solve
getinverse <- function() inverse
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
m$get()
m<-makeCacheMatrix()
m$set(mt)
m$get()
cacheSolve(mt)
mt<-matrix(c(2,3,5,0,0,1,1,0,1), nrow=3)
cacheSolve(mt)
## Put comments here that give an overall description of what your
## functions do
## makeCacheMAtrix and cacheSolve are functions that uses matrix and solve
## functions in R to make a function that caches the inverse of a matrix
## once it is solved.
## Write a short comment describing this function
## This function is something similar to a class, you have to
## "instantiate" it in a variable or symbol, and then access its inner
## functions as getters and setters.
## set() gives the value to the matrix, receiving a matrix as parameter
makeCacheMatrix <- function(x = matrix()) {
inverse<-NULL
set <- function(mtx) {
internmatrix <<- mtx
inverse <<- NULL
}
get <- function() internmatrix
setinverse <- function(solve) inverse <<- solve
getinverse <- function() inverse
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
## Write a short comment describing this function
## cacheSolve receives a symbol of makeCacheMatrix, and if the inverse
## matrix has already been calculated, then returns the value.
## If not, it calculates and asigns to the inverse value of makeCacheMatrix
## and returns the inverse matrix
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inverse <- x$getinverse()
if(!is.null(inverse)) {
message("getting cached data")
return(inverse)
}
data <- x$get()
inverse <- solve(data, ...)
x$setinverse(inverse)
inverse
}
cacheSolve(mt)
m<-makeCacheMatrix()
m$set(mt)
cacheSolve(m)
cacheSolve(m)
set.seed(1)
rpois(5,2)
install.packages("httr")
library(httr)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "e63bb290527d46c90cba")
install.packages("httpuv")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "e63bb290527d46c90cba", "5c3654b9410fca12324629c91463b15487a58a34")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("ggplot2")
xyplot
xyplot()
library(lattice)
xyplot()
x<-rnorm(100)
y<-rnorm(100)
plot (x,y)
xyplot(x~y)
class(xyplot(x~y))
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
g+geom_poit()
g+geom_point()
data(movies)
qplot(votes, rating, data = movies) + geom_smooth()
x <- c(3, 5, 1, 10, 12, 6)
x[x < 6] == 0
x
x[x < 6] <- 0
x
install.packages("KernSmooth")
library (KernSmooth)
setwd("~/")
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
if (! file.exists("/FDGP.csv")){
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="/FDGP.csv")
}
if (! file.exists("/statscountry.csv")){
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv ", destfile="/statscountry.csv")
}
options(stringsAsFactors = FALSE)
FGDP<-read.csv("/FDGP.csv")
stcountry<-read.csv("/statscountry.csv")
FGDP1<-FGDP[5:194,]
FGDP1$Gross.domestic.product.2012<-as.numeric(FGDP1$Gross.domestic.product.2012)
library(reshape2)
mergedData=merge(FGDP1,stcountry,by.x="X",by.y="CountryCode",all=TRUE)
mergedData$Gross.domestic.product.2012<-as.numeric(mergedData$Gross.domestic.product.2012)
orderedData<-mergedData[order(-mergedData$Gross.domestic.product.2012),]
orderedData$X.2[13]
dim(orderedData)
qGroups<-quantile(mergedData$Gross.domestic.product.2012,probs=c(.2,.4,.6,.8,1), na.rm=TRUE)
if (! file.exists("/FDGP.csv")){
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="/FDGP.csv")
}
if (! file.exists("/statscountry.csv")){
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv ", destfile="/statscountry.csv")
}
options(stringsAsFactors = FALSE)
FGDP<-read.csv("/FDGP.csv")
stcountry<-read.csv("/statscountry.csv")
FGDP1<-FGDP[5:194,]
FGDP1$Gross.domestic.product.2012<-as.numeric(FGDP1$Gross.domestic.product.2012)
library(reshape2)
mergedData=merge(FGDP1,stcountry,by.x="X",by.y="CountryCode",all=TRUE)
mergedData$Gross.domestic.product.2012<-as.numeric(mergedData$Gross.domestic.product.2012)
orderedData<-mergedData[order(-mergedData$Gross.domestic.product.2012),]
orderedData$X.2[13]
avgNOECD<-mergedData[(mergedData$Income.Group=="High income: nonOECD"),]
avgOECD<-mergedData[(mergedData$Income.Group=="High income: OECD"),]
mean(sapply(avgNOECD$Gross.domestic.product.2012, as.numeric), na.rm=TRUE)
mean(sapply(avgOECD$Gross.domestic.product.2012, as.numeric), na.rm=TRUE)
qGroups<-quantile(mergedData$Gross.domestic.product.2012,probs=c(.2,.4,.6,.8,1), na.rm=TRUE)
qGroups
tGroups<-cut(mergedData$Gross.domestic.product.2012,breaks=5)
tGroups
table(tGroups)
stringAsFactors = FALSE
#Read all files and asing them to symbols
xtrain<-read.table("UCI HAR Dataset/train/x_train.txt")
ylabels<-read.table("UCI HAR Dataset/train/y_train.txt")
subject<-read.table("UCI HAR Dataset/train/subject_train.txt")
activities<-read.table("UCI HAR Dataset/activity_labels.txt")
xtraint<-read.table("UCI HAR Dataset/test/x_test.txt")
ylabelst<-read.table("UCI HAR Dataset/test/y_test.txt")
subjectt<-read.table("UCI HAR Dataset/test/subject_test.txt")
features<-read.table("UCI HAR Dataset/features.txt")
#adding activity columns to datasets
dat_train<-cbind(ylabels,xtrain)
dat_test<-cbind(ylabelst,xtraint)
#adding subject column
dat_train<-cbind(subject,dat_train)
dat_test<-cbind(subjectt,dat_test)
#put all toguether
testAndTrainData<-rbind(dat_train,dat_test)
#naming the columns
names(testAndTrainData)[1]<-"subject"
names(testAndTrainData)[2]<-"activity"
names(testAndTrainData)[3:563]<-as.vector(t(features[[2]]))
#change labels for activity names
factors<-factor(testAndTrainData$activity)
levels(factors)<-activities[[2]]
testAndTrainData$activity<-factors
#filtering mean and standar deviation columns
filters<-testAndTrainData
for (i in 1:length(names(filters))){
names(filters)[i]<-gsub("meanFreq|gravityMean|tBodyAccMean,|tBodyAccJerkMean|tBodyGyroMean,|tBodyGyroJerkMean","delete",names(filters)[i])
}
meanStdIndices<-grep("activity|subject|[Mm]ean|[Ss]td",names(filters))
meanStdData<-filters[,meanStdIndices]
#Renaming columns
for (i in 1:length(names(meanStdData))){
names(meanStdData)[i]<-gsub("-","_",names(meanStdData)[i])
names(meanStdData)[i]<-gsub("[()]","",names(meanStdData)[i])
names(meanStdData)[i]<-tolower(gsub(",","_",names(meanStdData)[i]))
}
#write the file with tidyData
write.table(meanStdData,"tidyData.txt", row.names=FALSE)
#test the file
reread <- read.table("tidyData.txt", header = TRUE)
nrow(meanStdData) == nrow(reread)
ncol(meanStdData) == ncol(reread)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
??lines
??lines()
??trellis.par.set()
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(ggplot)
library(ggplot2)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
g <- ggplot(movies, aes(votes, rating))
g
??lines
??axis
with(hpc,
plot(Date + Time,
Global_active_power,
type = "l",
ylab = "Global Active Power (kilowatts)",
xlab = ""))
??lpoints()
lattice
??lattice
---
title: "PA1_template.Rmd"
author: "edjurado"
date: "Sunday, May 10, 2015"
output: html_document
---
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r}
summary(cars)
```
You can also embed plots, for example:
```{r, echo=FALSE}
plot(cars)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
setwd("D:/cursos/DataScienceSpecialization/05_reproducibleResearch/p1")
read.csv("activity.csv")
read.csv("/activity.csv")
setwd("D:/cursos/DataScienceSpecialization/05_reproducibleResearch/p1")
read.csv("/activity.csv")
read.csv("activity.csv")
read.csv("activity.csv")
setwd("D:/cursos/DataScienceSpecialization/05_reproducibleResearch/p1")
read.csv("activity.csv")
setwd("D:/cursos/DataScienceSpecialization/05_reproducibleResearch/p1/RepData_PeerAssessment1")
read.csv("activity.csv")
activity<-read.csv("activity.csv")
head(activity)
summary(activity)
mean(activity$steps,na.rm=true)
mean(activity$steps,na.rm=True)
mean(activity$steps,na.rm=TRUE)
activity$date
aggregate(activity$date,mean)
aggregate(activity$steps,list(activity$date),mean)
aggregate(activity$steps,list(activity$date),mean(na.rm=TRUE))
is.na(activity)
activity[!is.na(activity),
activity[!is.na(activity),
activity[!is.na(activity),]
activity[!is.na(activity),]
activity[!is.na(activity),]
actrmna<-activity[!is.na(activity),]
aggregate(actrmna$steps,list(actrmna$date),mea
actrmna<-activity[!is.na(activity),]
aggregate(actrmna$steps,list(actrmna$date),mean)
stepsMean<-aggregate(actrmna$steps,list(actrmna$date),mean)
hist(stepsMean)
hist(stepsMean$steps,stepsMean$date
hist(stepsMean$steps,stepsMean$date)
??hist
hist(stepsMean$steps)
hist(stepsMean$step)
type(TRUE)
class(TRUE)
class(stepsMean$step)
class(stepsMean$steps)
stepsMean
names(stepMeans)
names(stepsMean)
names(stepsMean)<-c("date","mean")
names(stepsMean)
hist(stepsMean$mean,stepsMean$date)
hist(actrmna$steps)
